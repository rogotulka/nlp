{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter_message_pos = pd.read_csv('data/positive.csv', sep=';', header=None)\n",
    "twitter_message_neg = pd.read_csv('data/negative.csv', sep=';', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>408906692374446080</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>pleease_shut_up</td>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7569</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408906692693221377</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>alinakirpicheva</td>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11825</td>\n",
       "      <td>59</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408906695083954177</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>EvgeshaRe</td>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1273</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>408906695356973056</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>ikonnikova_21</td>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1549</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408906761416867842</td>\n",
       "      <td>1386325943</td>\n",
       "      <td>JumpyAlex</td>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>597</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0           1                2   \\\n",
       "0  408906692374446080  1386325927  pleease_shut_up   \n",
       "1  408906692693221377  1386325927  alinakirpicheva   \n",
       "2  408906695083954177  1386325927        EvgeshaRe   \n",
       "3  408906695356973056  1386325927    ikonnikova_21   \n",
       "4  408906761416867842  1386325943        JumpyAlex   \n",
       "\n",
       "                                                  3   4   5   6   7      8   \\\n",
       "0  @first_timee хоть я и школота, но поверь, у на...   1   0   0   0   7569   \n",
       "1  Да, все-таки он немного похож на него. Но мой ...   1   0   0   0  11825   \n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...   1   0   1   0   1273   \n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...   1   0   1   0   1549   \n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...   1   0   0   0    597   \n",
       "\n",
       "   9   10  11  \n",
       "0  62  61   0  \n",
       "1  59  31   2  \n",
       "2  26  27   0  \n",
       "3  19  17   0  \n",
       "4  16  23   1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_message_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_message_all = pd.concat([twitter_message_neg, twitter_message_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter_message_all.columns = [\"id\", \"tdate\", \"tmane\", \"ttext\", \"ttype\", \"trep\", \"tfav\", \"tstcount\",\n",
    "                              \"trtw\", \"tfol\", \"tfrien\", \"listcount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_message_all = shuffle(twitter_message_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tdate</th>\n",
       "      <th>tmane</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "      <th>trep</th>\n",
       "      <th>tfav</th>\n",
       "      <th>tstcount</th>\n",
       "      <th>trtw</th>\n",
       "      <th>tfol</th>\n",
       "      <th>tfrien</th>\n",
       "      <th>listcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12269</th>\n",
       "      <td>410758723397640192</td>\n",
       "      <td>1386767485</td>\n",
       "      <td>gendalph945</td>\n",
       "      <td>Интернет не радует, YouTube со своими заморочк...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5621</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22841</th>\n",
       "      <td>411880361338355712</td>\n",
       "      <td>1387034905</td>\n",
       "      <td>hudeweje</td>\n",
       "      <td>RT @olugemygp: Спасибо всем, кто поправляет мо...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>193</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75142</th>\n",
       "      <td>410643380977553408</td>\n",
       "      <td>1386739986</td>\n",
       "      <td>Sashka_freedom</td>\n",
       "      <td>@_insense ладно, только я хз где достать норм ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3890</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25396</th>\n",
       "      <td>409560114971279360</td>\n",
       "      <td>1386481715</td>\n",
       "      <td>alekseykovalik</td>\n",
       "      <td>@Masha_Vilka хотел бы:) а еще хотел бы не испо...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9799</td>\n",
       "      <td>505</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72898</th>\n",
       "      <td>410487811943723008</td>\n",
       "      <td>1386702895</td>\n",
       "      <td>vikstiffmc</td>\n",
       "      <td>RT @Kusushayaa: Чувствую себя крутой Чикой, пр...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id       tdate           tmane  \\\n",
       "12269  410758723397640192  1386767485     gendalph945   \n",
       "22841  411880361338355712  1387034905        hudeweje   \n",
       "75142  410643380977553408  1386739986  Sashka_freedom   \n",
       "25396  409560114971279360  1386481715  alekseykovalik   \n",
       "72898  410487811943723008  1386702895      vikstiffmc   \n",
       "\n",
       "                                                   ttext  ttype  trep  tfav  \\\n",
       "12269  Интернет не радует, YouTube со своими заморочк...     -1     0     0   \n",
       "22841  RT @olugemygp: Спасибо всем, кто поправляет мо...     -1     0     3   \n",
       "75142  @_insense ладно, только я хз где достать норм ...      1     0     0   \n",
       "25396  @Masha_Vilka хотел бы:) а еще хотел бы не испо...      1     0     0   \n",
       "72898  RT @Kusushayaa: Чувствую себя крутой Чикой, пр...      1     0     1   \n",
       "\n",
       "       tstcount  trtw  tfol  tfrien  listcount  \n",
       "12269         0  5621    30      14          0  \n",
       "22841         0   388   193     194          0  \n",
       "75142         0  3890    93      93          0  \n",
       "25396         0  9799   505      74         14  \n",
       "72898         0    37     3       5          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_message_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = twitter_message_all['ttype']\n",
    "del twitter_message_all['ttype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(twitter_message_all['ttext'], target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_clf = sklearn.pipeline.Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(random_state=12345))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# кастомный токенайзер: пытаемся очисть текст от пунктуации, ссылок и ников\n",
    "def twitter_tokenize(text):\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text) # удаляем ссылки\n",
    "    \n",
    "    if text.startswith('RT ') :\n",
    "        text = text.replace('RT ', '') # удаляем ретвиты\n",
    "        \n",
    "    text = re.sub(r'(^|[^@\\w])@(\\w{1,15})\\b','',text) # удаляем ники\n",
    "    \n",
    "    text = re.sub(r'[!\"#$%&\\'*\\+,-./:;<=>?\\^_`{|}~()]+',' ',text) # удаляем знаки препинания\n",
    "    \n",
    "    return [x for x in text.split(' ') if x != ''] # разделяем по пробелам и удаляем пустые токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# еще кастомный токенайзер: пытаемся ко всему прочему заменить смайлы на спец токены\n",
    "def twitter__with_smile_tokenize(text):\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text) # удаляем ссылки\n",
    "    \n",
    "    goog_smile_patterns = [')))', '))', ')',':‑)',':)',':-]',':]', ':-3', ':3', ':->', ':>','8-)', '8)', ':-}',':}',':o)',':c)',\n",
    "                           ':^)','=]','=)',':‑D',':D','8‑D','8D','x‑D','xD','X‑D','XD', '=D','=3','B^D', ':-))']\n",
    "    \n",
    "    bad_smile_patterns = ['(((', '((', '(', ':‑(', ':(', ':‑c', ':c', ':‑<', ':<',':‑[',':[', ':-||', '>:[', ':{', ':@', '>:(',\n",
    "                          ':\\'‑(',':\\'(', ':\\'‑)',':\\')', 'D‑\\':', 'D:<','D:','D8','D;','D=','DX']\n",
    "   \n",
    "    for smile in goog_smile_patterns:\n",
    "        text = text.replace(smile, ' GSMILE ')  # заменяем на спец токен\n",
    "        \n",
    "    for smile in bad_smile_patterns:\n",
    "        text = text.replace(smile, ' BSMILE ')  # заменяем на спец токен\n",
    "    \n",
    "    if text.startswith('RT ') :\n",
    "        text = text.replace('RT ', '') # удаляем ретвиты\n",
    "        \n",
    "    text = re.sub(r'(^|[^@\\w])@(\\w{1,15})\\b','',text) # удаляем ники\n",
    "    \n",
    "    text = re.sub(r'/:([a-z]{1,10}):/i', '', text) # удаляем смайлы типа :smile:\n",
    "    \n",
    "    text = re.sub(r'[!\"#$%&\\'*\\+,-./:;<=>?\\^_`{|}~]+',' ',text) # удаляем знаки препинания\n",
    "    \n",
    "    \n",
    "    return [x for x in text.split(' ') if x != ''] # разделяем по пробелам и удаляем пустые токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Интернет не радует, YouTube со своими заморочками тоже. Так себе  настроенице :(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Интернет',\n",
       " 'не',\n",
       " 'радует',\n",
       " 'YouTube',\n",
       " 'со',\n",
       " 'своими',\n",
       " 'заморочками',\n",
       " 'тоже',\n",
       " 'Так',\n",
       " 'себе',\n",
       " 'настроенице']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка работы токенайзера\n",
    "print(twitter_message_all['ttext'].iloc[0])\n",
    "twitter_tokenize(twitter_message_all['ttext'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @olugemygp: Спасибо всем, кто поправляет мои ошибки в блоге. Да, я действительно забыл русский язык :(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Спасибо',\n",
       " 'всем',\n",
       " 'кто',\n",
       " 'поправляет',\n",
       " 'мои',\n",
       " 'ошибки',\n",
       " 'в',\n",
       " 'блоге',\n",
       " 'Да',\n",
       " 'я',\n",
       " 'действительно',\n",
       " 'забыл',\n",
       " 'русский',\n",
       " 'язык',\n",
       " 'BSMILE']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(twitter_message_all['ttext'].iloc[1])\n",
    "twitter__with_smile_tokenize(twitter_message_all['ttext'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# для русского языка загрузим стоп-слова\n",
    "with open('stop_words_ru.txt') as f:\n",
    "    stop_words = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# перберем gridsearch наши токенайзеры и параметры, чтобы найти оптимальное сочитание\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__stop_words': (None, stop_words),\n",
    "    'vect__tokenizer' : (None, twitter_tokenize, twitter__with_smile_tokenize),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...  penalty='l2', power_t=0.5, random_state=12345, shuffle=True,\n",
       "       verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'vect__stop_words': (None, ['c', 'а', 'алло', 'без', 'белый', 'близко', 'более', 'больше', 'большой', 'будем', 'будет', 'будете', 'будешь', 'будто', 'буду', 'будут', 'будь', 'бы', 'бывает', 'бывь', 'был', 'была', 'были', 'было', 'быть', 'в', 'важная', 'важное', 'важные', 'важный', 'вам',...d0fc510>, <function twitter__with_smile_tokenize at 0x1010dd840>), 'vect__max_df': (0.5, 0.75, 1.0)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5, random_state=12345, shuffle=True,\n",
       "        verbose=0, warm_start=False),\n",
       " 'clf__alpha': 0.0001,\n",
       " 'clf__average': False,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__epsilon': 0.1,\n",
       " 'clf__eta0': 0.0,\n",
       " 'clf__fit_intercept': True,\n",
       " 'clf__l1_ratio': 0.15,\n",
       " 'clf__learning_rate': 'optimal',\n",
       " 'clf__loss': 'hinge',\n",
       " 'clf__n_iter': 5,\n",
       " 'clf__n_jobs': 1,\n",
       " 'clf__penalty': 'l2',\n",
       " 'clf__power_t': 0.5,\n",
       " 'clf__random_state': 12345,\n",
       " 'clf__shuffle': True,\n",
       " 'clf__verbose': 0,\n",
       " 'clf__warm_start': False,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "           dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "           lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "           ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "           strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "           tokenizer=<function twitter__with_smile_tokenize at 0x1010dd840>,\n",
       "           vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('clf',\n",
       "   SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "          eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "          learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "          penalty='l2', power_t=0.5, random_state=12345, shuffle=True,\n",
       "          verbose=0, warm_start=False))],\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=<function twitter__with_smile_tokenize at 0x1010dd840>,\n",
       "         vocabulary=None),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.twitter__with_smile_tokenize>,\n",
       " 'vect__vocabulary': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# наш токенайзер со смайлами дал самый лучший результат на gridsearch\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# возьмем лучший estimator и проверим на тестовой выборке и посмотрим на метрики\n",
    "predicted = grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.97      0.98     22286\n",
      "          1       0.97      1.00      0.98     23081\n",
      "\n",
      "avg / total       0.98      0.98      0.98     45367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# получили интересное качество\n",
    "print(sklearn.metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21559,   727,    38, 23043])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(y_test, predicted).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_params_from_gridsearch(best_parameters, begin_prefix):\n",
    "    vect_params = {}\n",
    "    for key, value in best_parameters.items():\n",
    "        if key.startswith(begin_prefix):\n",
    "            key = key.replace(begin_prefix, '')\n",
    "            vect_params[key] = value\n",
    "    return vect_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# воссоздаем весь пайплайн, но меняем токенайзер на вуфолтный, чтобы сравнить с токенайзером, который читерил со смайлами\n",
    "vect = CountVectorizer()\n",
    "vect.set_params(**get_params_from_gridsearch(best_parameters, 'vect__'))\n",
    "vect.tokenizer = None\n",
    "tfidf = TfidfTransformer()\n",
    "tfidf.set_params(**get_params_from_gridsearch(best_parameters, 'tfidf__'))\n",
    "clf = SGDClassifier()\n",
    "clf.set_params(**get_params_from_gridsearch(best_parameters, 'clf__'))\n",
    "text_clf = sklearn.pipeline.Pipeline(([('vect', vect), \n",
    "                                       ('tfidf', tfidf),\n",
    "                                        ('clf', clf)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.75      0.65      0.70     22286\n",
      "          1       0.70      0.79      0.74     23081\n",
      "\n",
      "avg / total       0.73      0.72      0.72     45367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# получили ожидаемо ниже\n",
    "print(sklearn.metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# воссоздаем весь пайплайн, но меняем токенайзер на twitter_tokenize, чтобы сравнить с токенайзером, который читерил со смайлами\n",
    "vect.set_params(**get_params_from_gridsearch(best_parameters, 'vect__'))\n",
    "vect.tokenizer = twitter_tokenize\n",
    "tfidf = TfidfTransformer()\n",
    "tfidf.set_params(**get_params_from_gridsearch(best_parameters, 'tfidf__'))\n",
    "clf = SGDClassifier()\n",
    "clf.set_params(**get_params_from_gridsearch(best_parameters, 'clf__'))\n",
    "text_clf = sklearn.pipeline.Pipeline(([('vect', vect), \n",
    "                                       ('tfidf', tfidf),\n",
    "                                        ('clf', clf)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.74      0.71      0.73     22286\n",
      "          1       0.73      0.76      0.75     23081\n",
      "\n",
      "avg / total       0.74      0.74      0.74     45367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# получили ожидаемо ниже, но лучше, чем с дефолтный токенайзером\n",
    "print(sklearn.metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# вывод, который могу сделать, предобработка текста в данном примере сыграло ключевую роль, выделение смайликов \n",
    "# как отдельных токенов дало максимальный прирост в качестве классификатора сентимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
